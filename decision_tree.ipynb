{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lê o dataset de 4000 vítimas, X(qPa, pulso e frequencia respiratória), y(gravidade)\n",
    "\n",
    "file_path = 'datasets/4000.txt'\n",
    "X = []\n",
    "y = []\n",
    "# Ler e processar cada linhawithopen(file_path, 'r') as file:\n",
    "with open(file_path, 'r') as file:\n",
    "     for line in file:\n",
    "         # Separar os valores por vírgula\n",
    "         values = line.strip().split(',')\n",
    "        \n",
    "         # Extrair as características (colunas 1 a 6) e o rótulo (última coluna)\n",
    "         features = list(map(float, values[3:6]))  # Converta as características para float\n",
    "         label = int(values[7])  # Converta o rótulo para inteiro# Adicionar as características e rótulo às listas\n",
    "         label = label - 1  # Ajustar o rótulo para começar em 0\n",
    "         X.append(features)\n",
    "         y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lê o dataset de 4000 vítimas, X2(qPa, pulso e frequencia respiratória), y2(gravidade)\n",
    "\n",
    "file_path2 = 'datasets/800.txt'\n",
    "X2 = []\n",
    "y2 = []\n",
    "# Ler e processar cada linhawithopen(file_path, 'r') as file:\n",
    "with open(file_path2, 'r') as file:\n",
    "     for line in file:\n",
    "         # Separar os valores por vírgula\n",
    "         values = line.strip().split(',')\n",
    "        \n",
    "         # Extrair as características (colunas 1 a 6) e o rótulo (última coluna)\n",
    "         features = list(map(float, values[3:6]))  # Converta as características para float\n",
    "         label = int(values[7])  # Converta o rótulo para inteiro# Adicionar as características e rótulo às listas\n",
    "         label = label - 1  # Ajustar o rótulo para começar em 0\n",
    "         X2.append(features)\n",
    "         y2.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostras iniciais do dataframe\n",
      "        qPa       pulse  respiratory_freq\n",
      "0  8.652291  122.324349          5.623564\n",
      "1  8.733333  135.824333         12.787053\n",
      "2  8.733333   97.100546          1.553286\n"
     ]
    }
   ],
   "source": [
    "# Cria o dataframe de 4000 vitimas SEM a gravidade\n",
    "df = pd.DataFrame(X, columns = ['qPa','pulse','respiratory_freq'])\n",
    "print(\"Amostras iniciais do dataframe\")\n",
    "print(df.head(3)) # imprime 3 amostras do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostras iniciais do dataframe 800\n",
      "        qPa       pulse  respiratory_freq\n",
      "0  8.721732  160.904175         20.926336\n",
      "1  8.733333  134.454047         17.972046\n",
      "2  8.614814   86.302237          4.168373\n"
     ]
    }
   ],
   "source": [
    "# Cria o dataframe de 800 vitimas SEM a gravidade\n",
    "df2 = pd.DataFrame(X2, columns = ['qPa','pulse','respiratory_freq'])\n",
    "print(\"Amostras iniciais do dataframe 800\")\n",
    "print(df2.head(3)) # imprime 3 amostras do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho total do dataset: 4000\n",
      "\n",
      "Dados de treinamento X (3000):\n",
      "[[4.358461, 145.99551, 15.178772], [-4.385294, 155.005138, 15.287787], [-8.709306, 16.292285, 17.436375]] ...\n",
      "Dados de treinamento y:(3000)\n",
      " [2, 2, 1] ...\n",
      "---\n",
      "Dados de teste   X (1000):\n",
      "[[4.685739, 24.375112, 18.209474], [-4.399409, 82.247291, 7.246955], [8.733333, 113.558415, 17.34836]] ...\n",
      "Dados de teste   y:(1000)\n",
      " [1, 1, 1] ...\n"
     ]
    }
   ],
   "source": [
    "## Dividir o dataset em treinamento/validação e teste\n",
    "## É usual designar a entrada por X e a saída por y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=42)#utilizado random state 42 para manter constante\n",
    "print(f\"Tamanho total do dataset: {len(X)}\\n\")\n",
    "print(f\"Dados de treinamento X ({len(X_train)}):\\n{X_train[:3]} ...\")\n",
    "print(f\"Dados de treinamento y:({len(y_train)})\\n {y_train[:3]} ...\")\n",
    "print(\"---\")\n",
    "print(f\"Dados de teste   X ({len(X_test)}):\\n{X_test[:3]} ...\")\n",
    "print(f\"Dados de teste   y:({len(y_test)})\\n {y_test[:3]} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV 1/3] END criterion=entropy, max_depth=2, min_samples_leaf=8;, score=0.617 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=2, min_samples_leaf=8;, score=0.620 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=2, min_samples_leaf=8;, score=0.625 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=2, min_samples_leaf=16;, score=0.617 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=2, min_samples_leaf=16;, score=0.620 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=2, min_samples_leaf=16;, score=0.625 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=2, min_samples_leaf=32;, score=0.617 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=2, min_samples_leaf=32;, score=0.620 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=2, min_samples_leaf=32;, score=0.625 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=2, min_samples_leaf=64;, score=0.617 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=2, min_samples_leaf=64;, score=0.620 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=2, min_samples_leaf=64;, score=0.625 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, min_samples_leaf=8;, score=0.779 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, min_samples_leaf=8;, score=0.769 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, min_samples_leaf=8;, score=0.774 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, min_samples_leaf=16;, score=0.769 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, min_samples_leaf=16;, score=0.769 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, min_samples_leaf=16;, score=0.768 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, min_samples_leaf=32;, score=0.771 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, min_samples_leaf=32;, score=0.767 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, min_samples_leaf=32;, score=0.764 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, min_samples_leaf=64;, score=0.761 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, min_samples_leaf=64;, score=0.758 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, min_samples_leaf=64;, score=0.747 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=8, min_samples_leaf=8;, score=0.901 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=8, min_samples_leaf=8;, score=0.900 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=8, min_samples_leaf=8;, score=0.904 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=8, min_samples_leaf=16;, score=0.878 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=8, min_samples_leaf=16;, score=0.897 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=8, min_samples_leaf=16;, score=0.889 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=8, min_samples_leaf=32;, score=0.881 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=8, min_samples_leaf=32;, score=0.875 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=8, min_samples_leaf=32;, score=0.865 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=8, min_samples_leaf=64;, score=0.827 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=8, min_samples_leaf=64;, score=0.831 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=8, min_samples_leaf=64;, score=0.807 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=16, min_samples_leaf=8;, score=0.906 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=16, min_samples_leaf=8;, score=0.897 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=16, min_samples_leaf=8;, score=0.908 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=16, min_samples_leaf=16;, score=0.878 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=16, min_samples_leaf=16;, score=0.893 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=16, min_samples_leaf=16;, score=0.886 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=16, min_samples_leaf=32;, score=0.881 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=16, min_samples_leaf=32;, score=0.875 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=16, min_samples_leaf=32;, score=0.865 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=16, min_samples_leaf=64;, score=0.827 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=16, min_samples_leaf=64;, score=0.831 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=16, min_samples_leaf=64;, score=0.807 total time=   0.0s\n",
      "\n",
      "* Melhor classificador *\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, min_samples_leaf=8,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Parameters' definition\n",
    "parameters = {\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [2, 4, 8, 16],\n",
    "    'min_samples_leaf': [8, 16, 32, 64]\n",
    "}\n",
    "\n",
    "# instantiate model\n",
    "# random_state = 42 to be deterministic\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# grid search using cross-validation\n",
    "# cv = 3 is the number of folds\n",
    "# scoring = 'accuracy' the metric for chosing the best model\n",
    "clf = GridSearchCV(model, parameters, cv=3, scoring='accuracy', verbose=4)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# the best tree according to the accuracy score\n",
    "best = clf.best_estimator_\n",
    "print(\"\\n* Melhor classificador *\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia com dados de treino: 95.90%\n",
      "Acuracia com dados de teste: 92.00%\n",
      "Acuracia com dados 800: 91.62%\n"
     ]
    }
   ],
   "source": [
    "# Predicoes\n",
    "# com dados do treinamento\n",
    "y_pred_train = best.predict(X_train)\n",
    "acc_train = accuracy_score(y_train, y_pred_train) * 100\n",
    "print(f\"Acuracia com dados de treino: {acc_train:.2f}%\")\n",
    "\n",
    "# com dados de teste (nao utilizados no treinamento/validacao)\n",
    "y_pred_test = best.predict(X_test)\n",
    "acc_test = accuracy_score(y_test, y_pred_test) * 100\n",
    "print(f\"Acuracia com dados de teste: {acc_test:.2f}%\")\n",
    "\n",
    "# com dados do dataset de 800 vitimas\n",
    "y_pred_test = best.predict(X2)\n",
    "acc_test2 = accuracy_score(y2, y_pred_test) * 100\n",
    "print(f\"Acuracia com dados 800: {acc_test2:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O melhor classificador encontrado com score = accuracy:\n",
    "DecisionTreeClassifier(criterion='entropy', max_depth=16, min_samples_leaf=8, random_state=42)\n",
    "### Com uma acuracia de:\n",
    "91.62% "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

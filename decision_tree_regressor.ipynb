{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor, predicts the gravity, 0 to 100 (float)\n",
    "## O melhor classificador encontrado com scoring = neg_mean_squared_error:\n",
    "DecisionTreeRegressor(criterion='poisson', max_depth=16, min_samples_leaf=8,\n",
    "                      random_state=42)\n",
    "\n",
    "### Resultados:\n",
    "- MAE com dados de 800 vítimas: 2.102206<br />\n",
    "Em média, as previsões estão erradas por cerca de 2.10 unidades da verdade.<br />\n",
    "- MSE com dados de 800 vítimas: 11.301262<br />\n",
    "Há algum nível de erro, com erros maiores afetando mais o valor total.<br />\n",
    "- RMSE com dados de 800 vítimas: 3.361735<br />\n",
    "O erro típico de previsão é de cerca de 3.36 unidades.<br />\n",
    "- R² com dados de 800 vítimas: 0.956811<br />\n",
    "O modelo explica aproximadamente 95.68% da variância dos dados.<br />\n",
    "\n",
    "### Análises:\n",
    "#### Overfitting:\n",
    "O modelo pode estar sobreajustado aos dados de treinamento, resultando em um desempenho ligeiramente pior em dados não vistos.\n",
    "#### Underfitting:\n",
    "O modelo está apresentando um bom desempenho em todos os conjuntos de dados, embora o desempenho em dados não vistos seja ligeiramente pior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lê o dataset de 4000 vítimas, X(qPa, pulso e frequencia respiratória), y(gravidade)\n",
    "\n",
    "file_path = 'datasets/4000.txt'\n",
    "X = []\n",
    "y = []\n",
    "# Ler e processar cada linhawithopen(file_path, 'r') as file:\n",
    "with open(file_path, 'r') as file:\n",
    "     for line in file:\n",
    "         # Separar os valores por vírgula\n",
    "         values = line.strip().split(',')\n",
    "        \n",
    "         # Extrair as características (colunas 1 a 6) e o rótulo (última coluna)\n",
    "         features = list(map(float, values[3:6]))  # Converta as características para float\n",
    "         #label = int(values[7])  # Gravity class - Converta o rótulo para inteiro# Adicionar as características e rótulo às listas\n",
    "         #label = label - 1  # Gravity class - Ajustar o rótulo para começar em 0\n",
    "         label = float(values[6])\n",
    "         X.append(features)\n",
    "         y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lê o dataset de 4000 vítimas, X2(qPa, pulso e frequencia respiratória), y2(gravidade)\n",
    "\n",
    "file_path2 = 'datasets/800.txt'\n",
    "X2 = []\n",
    "y2 = []\n",
    "# Ler e processar cada linhawithopen(file_path, 'r') as file:\n",
    "with open(file_path2, 'r') as file:\n",
    "     for line in file:\n",
    "         # Separar os valores por vírgula\n",
    "         values = line.strip().split(',')\n",
    "        \n",
    "         # Extrair as características (colunas 1 a 6) e o rótulo (última coluna)\n",
    "         features = list(map(float, values[3:6]))  # Converta as características para float\n",
    "         #label = int(values[7])  # Gravity class - Converta o rótulo para inteiro# Adicionar as características e rótulo às listas\n",
    "         #label = label - 1  # Gravity class - Ajustar o rótulo para começar em 0\n",
    "         label = float(values[6])\n",
    "         X2.append(features)\n",
    "         y2.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostras iniciais do dataframe\n",
      "        qPa       pulse  respiratory_freq\n",
      "0  8.652291  122.324349          5.623564\n",
      "1  8.733333  135.824333         12.787053\n",
      "2  8.733333   97.100546          1.553286\n"
     ]
    }
   ],
   "source": [
    "# Cria o dataframe de 4000 vitimas SEM a gravidade\n",
    "df = pd.DataFrame(X, columns = ['qPa','pulse','respiratory_freq'])\n",
    "print(\"Amostras iniciais do dataframe\")\n",
    "print(df.head(3)) # imprime 3 amostras do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostras iniciais do dataframe 800\n",
      "        qPa       pulse  respiratory_freq\n",
      "0  8.721732  160.904175         20.926336\n",
      "1  8.733333  134.454047         17.972046\n",
      "2  8.614814   86.302237          4.168373\n"
     ]
    }
   ],
   "source": [
    "# Cria o dataframe de 800 vitimas SEM a gravidade\n",
    "df2 = pd.DataFrame(X2, columns = ['qPa','pulse','respiratory_freq'])\n",
    "print(\"Amostras iniciais do dataframe 800\")\n",
    "print(df2.head(3)) # imprime 3 amostras do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho total do dataset: 4000\n",
      "\n",
      "Dados de treinamento X (3000):\n",
      "[[4.358461, 145.99551, 15.178772], [-4.385294, 155.005138, 15.287787], [-8.709306, 16.292285, 17.436375]] ...\n",
      "Dados de treinamento y:(3000)\n",
      " [50.034547, 67.993565, 35.241338] ...\n",
      "---\n",
      "Dados de teste   X (1000):\n",
      "[[4.685739, 24.375112, 18.209474], [-4.399409, 82.247291, 7.246955], [8.733333, 113.558415, 17.34836]] ...\n",
      "Dados de teste   y:(1000)\n",
      " [39.082517, 49.826235, 49.382022] ...\n"
     ]
    }
   ],
   "source": [
    "## Dividir o dataset em treinamento/validação e teste\n",
    "## É usual designar a entrada por X e a saída por y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=42)#utilizado random state 42 para manter constante\n",
    "print(f\"Tamanho total do dataset: {len(X)}\\n\")\n",
    "print(f\"Dados de treinamento X ({len(X_train)}):\\n{X_train[:3]} ...\")\n",
    "print(f\"Dados de treinamento y:({len(y_train)})\\n {y_train[:3]} ...\")\n",
    "print(\"---\")\n",
    "print(f\"Dados de teste   X ({len(X_test)}):\\n{X_test[:3]} ...\")\n",
    "print(f\"Dados de teste   y:({len(y_test)})\\n {y_test[:3]} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV 1/3] END criterion=poisson, max_depth=2, min_samples_leaf=8;, score=-160.237 total time=   0.0s\n",
      "[CV 2/3] END criterion=poisson, max_depth=2, min_samples_leaf=8;, score=-159.910 total time=   0.0s\n",
      "[CV 3/3] END criterion=poisson, max_depth=2, min_samples_leaf=8;, score=-168.057 total time=   0.0s\n",
      "[CV 1/3] END criterion=poisson, max_depth=2, min_samples_leaf=16;, score=-160.237 total time=   0.0s\n",
      "[CV 2/3] END criterion=poisson, max_depth=2, min_samples_leaf=16;, score=-159.910 total time=   0.0s\n",
      "[CV 3/3] END criterion=poisson, max_depth=2, min_samples_leaf=16;, score=-168.057 total time=   0.0s\n",
      "[CV 1/3] END criterion=poisson, max_depth=2, min_samples_leaf=32;, score=-160.237 total time=   0.0s\n",
      "[CV 2/3] END criterion=poisson, max_depth=2, min_samples_leaf=32;, score=-159.910 total time=   0.0s\n",
      "[CV 3/3] END criterion=poisson, max_depth=2, min_samples_leaf=32;, score=-168.057 total time=   0.0s\n",
      "[CV 1/3] END criterion=poisson, max_depth=2, min_samples_leaf=64;, score=-160.237 total time=   0.0s\n",
      "[CV 2/3] END criterion=poisson, max_depth=2, min_samples_leaf=64;, score=-159.910 total time=   0.0s\n",
      "[CV 3/3] END criterion=poisson, max_depth=2, min_samples_leaf=64;, score=-168.057 total time=   0.0s\n",
      "[CV 1/3] END criterion=poisson, max_depth=4, min_samples_leaf=8;, score=-88.799 total time=   0.0s\n",
      "[CV 2/3] END criterion=poisson, max_depth=4, min_samples_leaf=8;, score=-86.553 total time=   0.0s\n",
      "[CV 3/3] END criterion=poisson, max_depth=4, min_samples_leaf=8;, score=-90.090 total time=   0.0s\n",
      "[CV 1/3] END criterion=poisson, max_depth=4, min_samples_leaf=16;, score=-88.801 total time=   0.0s\n",
      "[CV 2/3] END criterion=poisson, max_depth=4, min_samples_leaf=16;, score=-86.474 total time=   0.0s\n",
      "[CV 3/3] END criterion=poisson, max_depth=4, min_samples_leaf=16;, score=-90.090 total time=   0.0s\n",
      "[CV 1/3] END criterion=poisson, max_depth=4, min_samples_leaf=32;, score=-89.440 total time=   0.0s\n",
      "[CV 2/3] END criterion=poisson, max_depth=4, min_samples_leaf=32;, score=-86.368 total time=   0.0s\n",
      "[CV 3/3] END criterion=poisson, max_depth=4, min_samples_leaf=32;, score=-89.590 total time=   0.0s\n",
      "[CV 1/3] END criterion=poisson, max_depth=4, min_samples_leaf=64;, score=-89.922 total time=   0.0s\n",
      "[CV 2/3] END criterion=poisson, max_depth=4, min_samples_leaf=64;, score=-89.204 total time=   0.0s\n",
      "[CV 3/3] END criterion=poisson, max_depth=4, min_samples_leaf=64;, score=-92.714 total time=   0.0s\n",
      "[CV 1/3] END criterion=poisson, max_depth=8, min_samples_leaf=8;, score=-22.759 total time=   0.0s\n",
      "[CV 2/3] END criterion=poisson, max_depth=8, min_samples_leaf=8;, score=-20.674 total time=   0.0s\n",
      "[CV 3/3] END criterion=poisson, max_depth=8, min_samples_leaf=8;, score=-23.085 total time=   0.0s\n",
      "[CV 1/3] END criterion=poisson, max_depth=8, min_samples_leaf=16;, score=-26.750 total time=   0.0s\n",
      "[CV 2/3] END criterion=poisson, max_depth=8, min_samples_leaf=16;, score=-27.551 total time=   0.0s\n",
      "[CV 3/3] END criterion=poisson, max_depth=8, min_samples_leaf=16;, score=-29.024 total time=   0.0s\n",
      "[CV 1/3] END criterion=poisson, max_depth=8, min_samples_leaf=32;, score=-39.198 total time=   0.0s\n",
      "[CV 2/3] END criterion=poisson, max_depth=8, min_samples_leaf=32;, score=-34.672 total time=   0.0s\n",
      "[CV 3/3] END criterion=poisson, max_depth=8, min_samples_leaf=32;, score=-37.926 total time=   0.0s\n",
      "[CV 1/3] END criterion=poisson, max_depth=8, min_samples_leaf=64;, score=-58.360 total time=   0.0s\n",
      "[CV 2/3] END criterion=poisson, max_depth=8, min_samples_leaf=64;, score=-53.835 total time=   0.0s\n",
      "[CV 3/3] END criterion=poisson, max_depth=8, min_samples_leaf=64;, score=-63.974 total time=   0.0s\n",
      "[CV 1/3] END criterion=poisson, max_depth=16, min_samples_leaf=8;, score=-15.155 total time=   0.0s\n",
      "[CV 2/3] END criterion=poisson, max_depth=16, min_samples_leaf=8;, score=-15.633 total time=   0.0s\n",
      "[CV 3/3] END criterion=poisson, max_depth=16, min_samples_leaf=8;, score=-15.938 total time=   0.0s\n",
      "[CV 1/3] END criterion=poisson, max_depth=16, min_samples_leaf=16;, score=-21.752 total time=   0.0s\n",
      "[CV 2/3] END criterion=poisson, max_depth=16, min_samples_leaf=16;, score=-24.218 total time=   0.0s\n",
      "[CV 3/3] END criterion=poisson, max_depth=16, min_samples_leaf=16;, score=-26.002 total time=   0.0s\n",
      "[CV 1/3] END criterion=poisson, max_depth=16, min_samples_leaf=32;, score=-38.514 total time=   0.0s\n",
      "[CV 2/3] END criterion=poisson, max_depth=16, min_samples_leaf=32;, score=-34.672 total time=   0.0s\n",
      "[CV 3/3] END criterion=poisson, max_depth=16, min_samples_leaf=32;, score=-36.397 total time=   0.0s\n",
      "[CV 1/3] END criterion=poisson, max_depth=16, min_samples_leaf=64;, score=-58.360 total time=   0.0s\n",
      "[CV 2/3] END criterion=poisson, max_depth=16, min_samples_leaf=64;, score=-53.835 total time=   0.0s\n",
      "[CV 3/3] END criterion=poisson, max_depth=16, min_samples_leaf=64;, score=-63.974 total time=   0.0s\n",
      "\n",
      "* Melhor classificador *\n",
      "DecisionTreeRegressor(criterion='poisson', max_depth=16, min_samples_leaf=8,\n",
      "                      random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Parameters' definition\n",
    "parameters = {\n",
    "    'criterion': ['poisson'], #, 'absolute_error', 'squared_error', 'friedman_mse'],\n",
    "    'max_depth': [2, 4, 8, 16],\n",
    "    #'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [8, 16, 32, 64]\n",
    "}\n",
    "#scoring_options = {\n",
    "#    'MSE': 'neg_mean_squared_error',\n",
    "#    'MAE': 'neg_mean_absolute_error',\n",
    "#    'RMSE': 'neg_root_mean_squared_error',\n",
    "#    'R2': 'r2'\n",
    "#}\n",
    "\n",
    "# instantiate model\n",
    "# random_state = 42 to be deterministic\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Best model found: DecisionTreeRegressor(criterion='poisson', max_depth=16, min_samples_leaf=8,\n",
    "#                      random_state=42)\n",
    "\n",
    "# grid search using cross-validation\n",
    "# cv = 3 is the number of folds\n",
    "# scoring = 'accuracy' the metric for chosing the best model\n",
    "clf = GridSearchCV(model, parameters, cv=3, scoring='neg_mean_squared_error', verbose=4)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# the best tree according to the accuracy score\n",
    "best = clf.best_estimator_\n",
    "print(\"\\n* Melhor classificador *\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE com dados de treino: 1.515655\n",
      "MSE com dados de treino: 5.660392\n",
      "RMSE com dados de treino: 2.379158\n",
      "R² com dados de treino: 0.977777\n",
      "MAE com dados de teste: 1.984884\n",
      "MSE com dados de teste: 9.964327\n",
      "RMSE com dados de teste: 3.156632\n",
      "R² com dados de teste: 0.961956\n",
      "MAE com dados de 800 vítimas: 2.102206\n",
      "MSE com dados de 800 vítimas: 11.301262\n",
      "RMSE com dados de 800 vítimas: 3.361735\n",
      "R² com dados de 800 vítimas: 0.956811\n"
     ]
    }
   ],
   "source": [
    "# Predicoes\n",
    "# com dados do treinamento\n",
    "y_pred_train = best.predict(X_train)\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(f\"MAE com dados de treino: {mae_train:.6f}\")\n",
    "print(f\"MSE com dados de treino: {mse_train:.6f}\")\n",
    "print(f\"RMSE com dados de treino: {rmse_train:.6f}\")\n",
    "print(f\"R² com dados de treino: {r2_train:.6f}\")\n",
    "\n",
    "# Predições com dados de teste\n",
    "y_pred_test = best.predict(X_test)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"MAE com dados de teste: {mae_test:.6f}\")\n",
    "print(f\"MSE com dados de teste: {mse_test:.6f}\")\n",
    "print(f\"RMSE com dados de teste: {rmse_test:.6f}\")\n",
    "print(f\"R² com dados de teste: {r2_test:.6f}\")\n",
    "\n",
    "# Predições com dados do dataset de 800 vítimas\n",
    "y_pred_test2 = best.predict(X2)\n",
    "mae_test2 = mean_absolute_error(y2, y_pred_test2)\n",
    "mse_test2 = mean_squared_error(y2, y_pred_test2)\n",
    "rmse_test2 = np.sqrt(mse_test2)\n",
    "r2_test2 = r2_score(y2, y_pred_test2)\n",
    "\n",
    "print(f\"MAE com dados de 800 vítimas: {mae_test2:.6f}\")\n",
    "print(f\"MSE com dados de 800 vítimas: {mse_test2:.6f}\")\n",
    "print(f\"RMSE com dados de 800 vítimas: {rmse_test2:.6f}\")\n",
    "print(f\"R² com dados de 800 vítimas: {r2_test2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Salvando o modelo\n",
    "if not os.path.exists('dt_regressor_models'):\n",
    "    os.mkdir('dt_regressor_models')\n",
    "\n",
    "joblib.dump(best, 'dt_regressor_models/best_regressor.pkl')\n",
    "with open(\"dt_regressor_models/models.txt\", \"w\") as file:\n",
    "    file.write(f'Config: {str(best)}\\nMAE com dados de 800 vítimas: {mae_test2:.6f}\\nMSE com dados de 800 vítimas: {mse_test2:.6f}\\nRMSE com dados de 800 vítimas:{rmse_test2:.6f}\\nR² com dados de 800 vítimas: {r2_test2:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE com dados de 800 vítimas: 2.102206\n",
      "MSE com dados de 800 vítimas: 11.301262\n",
      "RMSE com dados de 800 vítimas: 3.361735\n",
      "R² com dados de 800 vítimas: 0.956811\n"
     ]
    }
   ],
   "source": [
    "#Para carregar o modelo\n",
    "\n",
    "# Carregar o modelo salvo\n",
    "model = joblib.load('dt_regressor_models/best_regressor.pkl')\n",
    "\n",
    "# Agora você pode usar o modelo carregado para fazer previsões\n",
    "y_pred_test2 = model.predict(X2)\n",
    "mae_test2 = mean_absolute_error(y2, y_pred_test2)\n",
    "mse_test2 = mean_squared_error(y2, y_pred_test2)\n",
    "rmse_test2 = np.sqrt(mse_test2)\n",
    "r2_test2 = r2_score(y2, y_pred_test2)\n",
    "\n",
    "print(f\"MAE com dados de 800 vítimas: {mae_test2:.6f}\")\n",
    "print(f\"MSE com dados de 800 vítimas: {mse_test2:.6f}\")\n",
    "print(f\"RMSE com dados de 800 vítimas: {rmse_test2:.6f}\")\n",
    "print(f\"R² com dados de 800 vítimas: {r2_test2:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
